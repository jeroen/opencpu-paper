\section{The OpenCPU HTTP API}

One of the major strengths of \OpenCPU is that it builds on the Hypertext Transfer Protocol (\HTTP). \HTTP is the most used application protocol on the internet, and the foundation of data communication in browsers and the world wide web. The \HTTP specification is very mature, highly optimized and widely implemented. It provides all functionality required to build modern applications and has recently gained popularity for web \API's as well. The benefit if using a standardized application protocol such as \HTTP is that a lot of funtionality gets built-in by design. \HTTP has excellent mechanisms for authentication, encryption, caching, distribution, concurrency, error handling, etc. This allows us to defer appliation logic of our system to the \HTTP standards and limit the \OpenCPU \API definition to domain logic specific to scientific computing. The result is a simple and interoperable interface that is easy to learn and can be implemented with standard \HTTP software libraries. This is an enormous advantage over many other interfaces to \R and critical to make the system scalable and extensible. 

The \OpenCPU \API defines a mapping between \HTTP requests and high-level operations in scientific computing such as calling functions, running scripts, rendering \Latex, access to data, manual pages and management of files and objects. The \API specifically does not prescribe any language implementation details. Low-level concerns such as process management or code evaluation are abstracted and at the discretion of the server implementation. The \API also does describe any logic which can be taken care of on the protocol or application layer. For example, to add support for authentication, any of the standard mechanisms can be used such as \HTTP basic auth \citep{franks1999rfc} or OAuth 2.0 \citep{hardt2012oauth}. Implementing authentication methods might vary from a simple server configuration to defining additional endpoints. However authentication will not affect the \emph{meaning} of the \API itself and can therefore considered independent of our work. The same holds for many other features that are native to the \HTTP protocol, and can be used in conjunction with the \OpenCPU \API (or any other \HTTP \API for that matter). 

What remains after cutting out implementation and application logic is a simple interface to scientific computing that separates client and server responsibility along the lines of domain expertise. The \OpenCPU \API consists of a minimal set of operations required to build applications while giving servers freedom to implement and optimize this functionality in a way that makes sense with the context of a particular computational language or environment. 

\subsection{Concepts}

As was described before, individual requests within the \OpenCPU \API are stateless and there is no notion of a \emph{process}. State of the system only changes through creation and manipulation of resources such as objects, graphics and files. This section introduces some conceptial entities and operations that the \OpenCPU \API defines.

\subsubsection{objects and namespaces}

Objects are the primary entities of the system and carry the same meaning as within the computation language. Objects are referred to with symbol or variable name which is unique within the namespace of the object. Each object has a unique \HTTP endpoint. The \API does not distinguish between static objects that appear in e.g. packages, or dynamic objects that get created when executing scripts or function calls, nor does it distinguish if an object exists in memory or on disk. The \API merely provides a system for referring to objects in a way that allows clients to control them, for example to retrieve the object in a particular output format, or use it as an argument in a function call.

A namespace is a path in the \API containing a collection of uniquely named objects. In \R, static namespaces exist in \emph{packages} and dynamic namespaces exist in \emph{environments} such as the the user workspace. The \API uses an abstract concept of a namespace which does not distinguish between static or dynamic, persistent or temporary namespaces. Clients can request a list of the contents of namespaces, although the server can refuse this request for private namespaces or hidden objects. 

\subsubsection{function calls}

Performing a \texttt{POST} request on a function object invokes a function call, where the \texttt{HTTP} parameters are mapped to function arguments. Arguments can be posted using one of several input formats. 

Objects are both the arguments and return value of function calls. When a client performs a remote function call, the server (not the client/user) determines the name and namespace that the output object is assigned to and includes this information in the response. Objects are non mutable and therefore the client can not change or overwrite existing objects. For function calls that modify the state of an object, the server creates a copy of the modified object under a new name and leave the original object is unaffected. In \R, the function call itself is also an object that can be stored alongside the output for reproducibility purposes. 

\subsection{graphics}

\subsection{manuals}

- formats

\subsection{files}

- read
- execute

\subsection{containers}
 
- packages
- sessions

\subsection{libraries}





- libraries / repositories
- namespaces / packages
- objects
- files
- manuals

-
- objects
- graphics
- exceptions
- stdout
- source
- files
- function call
- 



\subsection{Reference Implementation}

As part of the research, two reference implementations were developed. The \R package \texttt{opencpu} builds on the \texttt{httpuv} web server (another \R package) to implement a \emph{single-user server} which runs within an interactive R session on any platform. The \emph{cloud server} is a multi-user implementation based on \texttt{Linux} and \texttt{rApache}. The latter yields better performance and has advanced security and configuration options, however it requires a dedicated Ubuntu server. One major difference between these implementations is how they handle concurrency. Because \R is single threaded, \texttt{httpuv} handles only one request at a time. Additional incoming requests are automatically queued and executed in succession using the same process. The cloud server on the other hand takes advantage of multi-processing in the Apache2 web server to handle concurrency. This implementation uses forks of the R process to serve concurrent requests immediately with little performance overhead. 

The differences between the cloud server and single user server are invisible to clients. The OpenCPU API provides a standard interface to either implementation. Other than varying performance, applications will behave the same regardless of which server is used. This shows the strenght of the system: applications can be developed locally using the single user server and published later on a shared high-performance cloud server.

\subsection{Reproducbility by design}

Besides exposing high level logic to scientific computing, OpenCPU tries to incorporate the concept of reproducibility by design: in addition to results, the system automatically stores all input and output from all procedures. Hence, for each resource on the system, clients can lookup the code, data, warnings and packages that were involved in the creation of an object. Thereby each result can easily be recalculated, which forms a powerful foundation for reproducible practices. However this can also be used for other purposes. For example, if a procedure fetches dynamic data from an external resource to generate a model or plot, we can use reproduction to \emph{update} the model or plot with the latest data.

The importance and power of reproduction in scientific computing cannot be over-emphasized. Reprodibles could become the building block of collaborative science, analogous to a "commit" in software versioning. Reproducible resources make it natural for researchers to publish, fork, learn and teach results. The transition to embedded analysis provides a great opportunity to include better support for reproducible research in our software. By incorporating the notion of reproduction in the API, OpenCPU sets an example that turns reproduction into a native aspect of the interaction with the system. The current implementation is pretty basic, but it can be extended and is a proof of concept that illustrates the direction we should be headering.  

\subsection{Less is more}

\begin{quote}
\emph{``perfection is reached not when there is nothing left to add, but when there is nothing left to take away''} --- Antoine de Saint-Exupéry
\end{quote}

\vspace{8pt}

%KISS (\emph{``Keep it simple, stupid''}) is a popular ancronym coined in the 1960s by the U.S. Navy \citep{victor2007concise} for the design principle stating that systems work best if they are kept simple rather than made complicated. Some other frequently cited testimonials of similar observations include \emph{``less is more''} (Mies van der Rohe), \emph{``Simplicity is the ultimate sophistication''} (Leonardo da Vinci), and \emph{``perfection is reached not when there is nothing left to add, but when there is nothing left to take away''} (Antoine de Saint-Exupéry). 

\noindent Management of complexity is one of the most challenging aspects of modern software development. When pressure and temptation to expand functionality is not balanced by a constant strive for simplicity, a project is heading for failure. Each newly introduced feature demands additional testing, maintenance and support down the road, which can rapidly turn into a sinkhole of developer time. Moreover costs, overhead and limitations introduced by unwanted stuff make bloated software less attractive. Also programs gets increasingly difficult to learn and understand if important principles are masked by smoke screens, bells and whistles of vaguely related bonus features. Therefore finding a minimal generalizable solution to address a particular problem or market is key to software simplicity. However this is rarely easy. It requires careful deliberation of the role, scope and priorities of a system; of what it \emph{is} and what it should or should not do. Incomplete solutions that leave important problems unsolved are unreliable and impractical. However components that are overly involved might conflict with other pieces, and complicate the system. The quest for a clean and elegant design often consists of many iterations of adding, removing, abstracting, rethinking and refactoring the system.

For OpenCPU a lot of thought has gone into what are the fundamental building blocks of embedded scientific computing. The system should solve recurring problems and give structure to applications without imposing unnecessary limitations. The OpenCPU API sets out important guidelines on what is considered the responsibility of respectively the developer (client-side), statistician (server-side) and system itself (middle layer). For example, all \R functions and scripts accessible through the OpenCPU system. However, the API only specifies  procedures for remotely \emph{calling} such functions and \emph{retrieving} results. The specification does not mention any details on the behavior and implementation of functions or which data is exchanged. Other concerns such as authentication can be solved on the layer of the application protocol (i.e. HTTP). Hence even though useful, these are not fundamental to scientific computing specifically and therefore need no specification in our API. Finally the system has some meta-functionality such as reproducibility mentioned earlier. It is tempting to include more goodies such as permanent storage, system administration or front-end widgets. However, such features are not specific to scientific computing and can easily be realized as separate, independent software pieces. Therefore they do not need to be part of the specification either. 

OpenCPU is what remains after all non essential parts are taken away from the API. It defines a middle layer that addresses the core problems of embedded scientific computing, and nothing else. It specifies a system for management of resources and remote function calls over HTTP that isolates scientific computing from other parts of the system. It prescribes several data interchange formats, but no specific data types or structures. The system is intended to be used \emph{in conjunction} with other software such as database, web framework or administration tools. It is a powerful building block for stacks and applications with embedded analysis or visualization. 

\subsection{History of OpenCPU}

The OpenCPU specification outlined in this paper was not drafted overnight, but evolved as many iterations of trial and error. Initial inspirations were drawn from recurring problems in developing various \R web applications with \texttt{rApache}. Experiences from these applications revelealed fundamental challenges and domain logic of embedded scientific computing. The accumulated knowledge shaped a vision on what a system facilitating this entails that would eventually turn into OpenCPU.

After about a year of internal development, the first public version of OpenCPU appeared in August 2011. These alpha and beta versions were picked up by several early adopters, both from industry and academia, some of which are still in production today. The problems and critisim generated by these versions provided great feedback and revealed some fundamental design problems. At the same time exciting developments were going on in the \R community, in particular the rise of R-studio and introduction of influential \R packages \texttt{knitr}, \texttt{evaluate} and \texttt{httpuv}. These technologies provided more flexible and reliable foundations for OpenCPU than what was available than before. After a redesign of the API and a complete rewrite of the code, OpenCPU version  1.0 was released in August 2013. This version emphasizes simplicity and scalability by removing all non-essential functionality. What remains is an API that captures the core domain logic of embedded scientific computing. By making use of native features found in HTTP, the this version is flexible and extensible without getting bloated or overly complex.

