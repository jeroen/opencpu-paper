% !TEX root = interfacing.tex
\section{The OpenCPU HTTP API}

One of the major strengths of \OpenCPU is that it builds on the Hypertext Transfer Protocol (\HTTP). \HTTP is the most used application protocol on the internet, and the foundation of data communication in browsers and the world wide web. The \HTTP specification is very mature, highly optimized and widely implemented. It provides all functionality required to build modern applications and has recently gained popularity for web \API's as well. The benefit if using a standardized application protocol such as \HTTP is that a lot of funtionality gets built-in by design. \HTTP has excellent mechanisms for authentication, encryption, caching, distribution, concurrency, error handling, etc. This allows us to defer appliation logic of our system to the \HTTP standards and limit the \OpenCPU \API definition to domain logic specific to scientific computing. The result is a simple and interoperable interface that is easy to learn and can be implemented with standard \HTTP software libraries. This is an enormous advantage over many other interfaces to \R and critical to make the system scalable and extensible. 

The \OpenCPU \API defines a mapping between \HTTP requests and high-level operations in scientific computing such as calling functions, running scripts, rendering \Latex, access to data, manual pages and management of files and objects. The \API specifically does not prescribe any language implementation details. Low-level concerns such as process management or code evaluation are abstracted and at the discretion of the server implementation. The \API also does not describe any logic which can be taken care of on the protocol or application layer. For example, to add support for authentication, any of the standard mechanisms can be used such as \HTTP basic auth \citep{franks1999rfc} or OAuth 2.0 \citep{hardt2012oauth}. Implementing authentication methods might vary from a simple server configuration to defining additional endpoints. However authentication will not affect the \emph{meaning} of the \API itself and can therefore considered independent of our work. The same holds for many other native features of the \HTTP protocol which can be used in conjunction with the \OpenCPU \API (or any other \HTTP \API for that matter). 

What remains after cutting out implementation and application logic is a simple interface to scientific computing that separates client and server responsibility along the lines of domain expertise. The \OpenCPU \API consists of a minimal set of operations required to build applications while giving servers freedom to implement and optimize this functionality in a way that makes sense with the context of a particular computational language or environment. 

\subsection{Basic concepts}

This section introduces the principal entities and operations defined by the \API. As was described before, individual requests within the \OpenCPU \API are stateless and there is no notion of a \emph{process}. State of the system changes through creation and manipulation of resources such as objects, graphics and files. 

\subsubsection{Objects}

Objects are the primary entities of the system and carry the same meaning as within the computation language. All objects are referred to using a name which is unique in the namespace of the object. This gives each object within the \API a unique \HTTP endpoint. The \API does not distinguish between static objects that appear in e.g. packages, or dynamic objects that get created when executing scripts or function calls, nor does it distinguish between objects in memory or on disk. The \API merely provides a system for referencing objects in a way that allows clients to control them. Using reference keys, any object can be retrieved in a particular output format, or used as an argument in a function call. The server determines how these objects are persisted, if they are cached and when they expire.

\subsubsection{Namespaces}

A namespace is a collection of uniquely named objects with a given path in the \API. In \R, static namespaces are implemented using \emph{packages} and dynamic namespaces exist in \emph{environments} such as the user workspace. However \OpenCPU abstracts the concept of a namespace as any set of objects and does not distinguish between static or dynamic, persistent or temporary namespaces. Clients can request a list of the contents of namespaces, but the server can refuse this request for private namespaces or hidden objects. 

\subsubsection{Formats}

\OpenCPU explicitly differentiates a resource from a \emph{representation} of that resource in a particular \emph{format}. The \API lets the client (rather than the server) decide on the format used to serve content. This is a major improvement over current practices where data, documents and figures are usually exchanged in fixed format files. Resources in \OpenCPU can be retrieved using various output formats and formatting parameters. For example a basic dataset can be retrieved in \texttt{csv}, \texttt{json}, \texttt{Protocol Buffers} or \texttt{tab delimited} format. Similarly, a graphic can be retrieved in \texttt{svg}, \texttt{png} or \texttt{pdf} and manual pages can be retrieved in \texttt{text}, \texttt{html} or \texttt{pdf} format. In addition to the format, the client can specify formatting parameters in the request. For example for \texttt{png} format has parameters such as \texttt{width} and \texttt{height}, whereas the \texttt{tab delimited} format has parameters \texttt{sep}, \texttt{eol}, \texttt{dec} which specify the delimiting, end-of-line and decimal character respectively. The system supports many additional formats, but not every format is appropriate for every resource type. When a client requests a resource in a format using an invalid format, the server responds with an error. 

\subsubsection{RPC requests}

In the \OpenCPU system a \POST requests invokes a remote procedure call (\RPC). Requests targeting a \emph{function} object result in a function call where the \HTTP parameters from the post body are mapped to function \emph{arguments}. A \texttt{POST} request targeting a \emph{script} results in execution of the script where \HTTP parameters are mapped to the script interpreter. The current \OpenCPU implementation recognizes scripts by their file extension, and supports \R, \texttt{latex}, \texttt{markdown}, \texttt{Sweave} and \texttt{knitr} scripts. We use the term \RPC to refer to both remote function calls and remote script executions.

The \OpenCPU \API lets the server determine the name and namespace that outputs are assigned to and includes a key to these newly created resources in the response. Objects are non mutable and therefore the client can not change or overwrite existing objects. For function calls that modify the state of an object, the server creates a copy of the modified object under a new name and leave the original object is unaffected. Besides the return value, the server stores graphics, files, warnings, messages and \texttt{stdout} that were created during the function call. In \R, the function call itself is also an object that can be stored for reproducibility purposes. Each of these can be retrieved by the client using the same key as for the object.

\subsubsection{Arguments}

Arguments can be posted using one of several data interchange formats such as \JSON or \texttt{Protocol Buffers}. Alternatively the client can post a file or reference an existing object on the server as an argument.  





\subsubsection{Graphics}

Any function call can create zero or more graphics. After completing a remote function call, the server reports how many graphics were created and provide the client with a key for referencing these graphics. The client can retrieve each individual graphic in a subsequent requests using one of various output formats such as \texttt{png}, \texttt{pdf}, and \texttt{svg}. Where appropriate the client can specify additional formatting paramters during the retrieval of the graphic such as width, height or font size.

\subsubsection{Data}

The \API defines a seperate entity for \emph{data} objects. Even though data can technically be treated as general objects, it is often practical to be able to distinguish this special subclass. For example, \R packages implement lazy loading of data objects to save memory when using packages containing large datasets. Conceptually distinguishing data from executable objects (such as functions) can be helpful for applications that do not need to support \RPC functionality, and limit the system for data sharing purposes.

\subsubsection{Manuals}

In most scientific computing languages, each function or dataset that is available to the user is accompanied by an identically named manual page. This manual page includes information such as description and usage of functions and their arguments, or explanation and comments about the columns within a particular dataset. The \API defines a standard way of retrieving such manual pages in one of several formats, such as \texttt{text}, \texttt{html} or \texttt{pdf}.

\subsubsection{Files}

Using and manipulating files on disk is an integral part of the data analysis process. The \API incorporates files in several ways. First of all, clients can simply download files. Thereby it can retrieve files that were stored in the working directory as part in a remote function call. Support for hosting files also allows for exposing web pages (\texttt{html}, \texttt{css}, \texttt{js}) that interact with the other \API endpoints. 

Files can also be used as arguments within remote function calls. Any files contained in a post request using the \texttt{multipart/form-data} will be copied to the working directory before the function call is executed. The actual argument name in the function call is set to the \texttt{filename}. Thereby functions that require a file as one of their arguments can be called remotely just as easily as calling it locally. 

Finally, files that are recognized as \emph{scripts} can be executed through a \POST request. The main difference between calling a function and executing a script is that for the latter, \HTTP parameters are mapped to the script interpreter rather than function arguments. The current \OpenCPU implementation recognizes scripts from their file extension, and includes support for \R, \texttt{latex}, \texttt{markdown}, \texttt{Sweave} and \texttt{knitr} scripts. 


\subsubsection{containers and libraries}
 
We refer to a path on the server containing one or more of the above resources as a \emph{container}. The current \OpenCPU server implements two types of containers. A \emph{package} is a static container which may include a namespace with objects, manual pages, data and files. A \emph{session} is another container format which includes a namespace with objects, graphics and files. A session usually contains the outputs that were created from executing a script or function call. To the client there is no difference between the various container formats: interacting with an object or file works the same, regardless of whether it is part of a package or session.

Finally collection of containers is called a \emph{library}. In \R terminology, a library is a directory on disk with installed packages. However within the context of the \API, the term is more general. It refers to any set of containers, which in the current implementation can either be packages or sessions. Also the \API notion of a library does not require packages to be preintsalled. A remote set of packages, which in \R terminology is called a \emph{respository}, is also a library. The \API does not make this distinction and leaves it up to the server which types of libraries it wishes to expose. For example, the current implementation exposes the \texttt{CRAN} library, which to the client works exactly the same as any localy installed library. The server uses a combination of cronjobs and on-the-fly package installations to sync local installations with the remote \texttt{CRAN} repository. 


\subsection{Reference Implementation}

As part of the research, two reference implementations were developed. The \R package \texttt{opencpu} builds on the \texttt{httpuv} web server (another \R package) to implement a \emph{single-user server} which runs within an interactive R session on any platform. The \emph{cloud server} is a multi-user implementation based on \texttt{Linux} and \texttt{rApache}. The latter yields better performance and has advanced security and configuration options, however it requires a dedicated Ubuntu server. One major difference between these implementations is how they handle concurrency. Because \R is single threaded, \texttt{httpuv} handles only one request at a time. Additional incoming requests are automatically queued and executed in succession using the same process. The cloud server on the other hand takes advantage of multi-processing in the Apache2 web server to handle concurrency. This implementation uses forks of the R process to serve concurrent requests immediately with little performance overhead. 

The differences between the cloud server and single user server are invisible to clients. The OpenCPU API provides a standard interface to either implementation. Other than varying performance, applications will behave the same regardless of which server is used. This shows the strenght of the system: applications can be developed locally using the single user server and published later on a shared high-performance cloud server.

\subsection{Reproducbility by design}

Besides exposing high level logic to scientific computing, OpenCPU tries to incorporate the concept of reproducibility by design: in addition to results, the system automatically stores all input and output from all procedures. Hence, for each resource on the system, clients can lookup the code, data, warnings and packages that were involved in the creation of an object. Thereby each result can easily be recalculated, which forms a powerful foundation for reproducible practices. However this can also be used for other purposes. For example, if a procedure fetches dynamic data from an external resource to generate a model or plot, we can use reproduction to \emph{update} the model or plot with the latest data.

The importance and power of reproduction in scientific computing cannot be over-emphasized. Reprodibles could become the building block of collaborative science, analogous to a "commit" in software versioning. Reproducible resources make it natural for researchers to publish, fork, learn and teach results. The transition to embedded analysis provides a great opportunity to include better support for reproducible research in our software. By incorporating the notion of reproduction in the API, OpenCPU sets an example that turns reproduction into a native aspect of the interaction with the system. The current implementation is pretty basic, but it can be extended and is a proof of concept that illustrates the direction we should be headering.  

\subsection{Less is more}

\begin{quote}
\emph{``perfection is reached not when there is nothing left to add, but when there is nothing left to take away''} --- Antoine de Saint-Exupéry
\end{quote}

\vspace{8pt}

%KISS (\emph{``Keep it simple, stupid''}) is a popular ancronym coined in the 1960s by the U.S. Navy \citep{victor2007concise} for the design principle stating that systems work best if they are kept simple rather than made complicated. Some other frequently cited testimonials of similar observations include \emph{``less is more''} (Mies van der Rohe), \emph{``Simplicity is the ultimate sophistication''} (Leonardo da Vinci), and \emph{``perfection is reached not when there is nothing left to add, but when there is nothing left to take away''} (Antoine de Saint-Exupéry). 

\noindent Management of complexity is one of the most challenging aspects of modern software development. When pressure and temptation to expand functionality is not balanced by a constant strive for simplicity, a project is heading for failure. Each newly introduced feature demands additional testing, maintenance and support down the road, which can rapidly turn into a sinkhole of developer time. Moreover costs, overhead and limitations introduced by unwanted stuff make bloated software less attractive. Also programs gets increasingly difficult to learn and understand if important principles are masked by smoke screens, bells and whistles of vaguely related bonus features. Therefore finding a minimal generalizable solution to address a particular problem or market is key to software simplicity. However this is rarely easy. It requires careful deliberation of the role, scope and priorities of a system; of what it \emph{is} and what it should or should not do. Incomplete solutions that leave important problems unsolved are unreliable and impractical. However components that are overly involved might conflict with other pieces, and complicate the system. The quest for a clean and elegant design often consists of many iterations of adding, removing, abstracting, rethinking and refactoring the system.

For OpenCPU a lot of thought has gone into what are the fundamental building blocks of embedded scientific computing. The system should solve recurring problems and give structure to applications without imposing unnecessary limitations. The OpenCPU API sets out important guidelines on what is considered the responsibility of respectively the developer (client-side), statistician (server-side) and system itself (middle layer). For example, all \R functions and scripts accessible through the OpenCPU system. However, the API only specifies  procedures for remotely \emph{calling} such functions and \emph{retrieving} results. The specification does not mention any details on the behavior and implementation of functions or which data is exchanged. Other concerns such as authentication can be solved on the layer of the application protocol (i.e. HTTP). Hence even though useful, these are not fundamental to scientific computing specifically and therefore need no specification in our API. Finally the system has some meta-functionality such as reproducibility mentioned earlier. It is tempting to include more goodies such as permanent storage, system administration or front-end widgets. However, such features are not specific to scientific computing and can easily be realized as separate, independent software pieces. Therefore they do not need to be part of the specification either. 

OpenCPU is what remains after all non essential parts are taken away from the API. It defines a middle layer that addresses the core problems of embedded scientific computing, and nothing else. It specifies a system for management of resources and remote function calls over HTTP that isolates scientific computing from other parts of the system. It prescribes several data interchange formats, but no specific data types or structures. The system is intended to be used \emph{in conjunction} with other software such as database, web framework or administration tools. It is a powerful building block for stacks and applications with embedded analysis or visualization. 

\subsection{History of OpenCPU}

The OpenCPU specification outlined in this paper was not drafted overnight, but evolved as many iterations of trial and error. Initial inspirations were drawn from recurring problems in developing various \R web applications with \texttt{rApache}. Experiences from these applications revelealed fundamental challenges and domain logic of embedded scientific computing. The accumulated knowledge shaped a vision on what a system facilitating this entails that would eventually turn into OpenCPU.

After about a year of internal development, the first public version of OpenCPU appeared in August 2011. These alpha and beta versions were picked up by several early adopters, both from industry and academia, some of which are still in production today. The problems and critisim generated by these versions provided great feedback and revealed some fundamental design problems. At the same time exciting developments were going on in the \R community, in particular the rise of R-studio and introduction of influential \R packages \texttt{knitr}, \texttt{evaluate} and \texttt{httpuv}. These technologies provided more flexible and reliable foundations for OpenCPU than what was available than before. After a redesign of the API and a complete rewrite of the code, OpenCPU version  1.0 was released in August 2013. This version emphasizes simplicity and scalability by removing all non-essential functionality. What remains is an API that captures the core domain logic of embedded scientific computing. By making use of native features found in HTTP, the this version is flexible and extensible without getting bloated or overly complex.

