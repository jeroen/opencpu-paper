% !TEX root = main.tex
\section{The state problem}

Management of \emph{state} is a fundamental principle around which digital communications are designed. We distinguish \emph{stateful} and \emph{stateless} communication. In a stateless communication protocol, interaction involves independent request-response messages in which each request is unrelated by any previous request \citep{hennessy2012computer}. Because the messages are independent, there is no particular ordering to them, and requests can be performed concurrently. Examples of stateless protcols include the Internet Protocol (\IP), and the Hypertext Transfer Protocol (\HTTP). A stateful protocol on the other hand consists of an interaction via an ordered sequence of interrelated messages. The specification typically prescribes a specific mechanism for initiating and terminating a persistent \emph{connection} for information exchange. Examples of stateful protocols include the Transmission Control Protocol (\TCP) or File Transfer Protocol (\texttt{FTP}).

%Different notions of state can exist in different layers of communications. For example \TCP provides stateful connections in a layer on top \texttt{IP}, by specifying procedures for labeling and ordering \IP messages. Conversely, \HTTP is a stateless application layer that builds on \TCP. When using \HTTP, requests are independent of each other and not part of a persistent connection. However, many websites that use \HTTP do require some notion of state, for example to distinguish between requests from various authenticated users. In such applications, the client typically includes a special session-key in the payload of each \HTTP request. This key a unique value that helps the server determine which requests were part of one and the same session which allows the server to retain the state of each such user session.

In most data analysis software, the user controls a interactive session through a console or \GUI, with the possibility of executing a predefined sequence of operations in the form of a \emph{script}. Scripts are useful for publishing code or restoring state, however the most common and powerful way to use the software is interactively. In this respect, scientific computing is not unlike to a \emph{shell} interface to the operating system. Interactivity in scientific computing makes managment of state the most central challenge in the interface design. When moving from a \UI to \API perspective, supporting statefulness become substantially more complicated. Existing bridges to \R have implemented one of two basic approaches discussed below. 

\subsection{Stateless solutions: predefined scripts}

The easiest solution is to not incorporate state on the level of the interface, and limit the system to predefined scripts. This is the standard approach in traditional web development. The web server exposes a parameratized service which generates dynamic content by calling out to a script on the system via \CGI. Any support for state has to be implemented manually in the application layer, e.g. by writing code that stores values in a database. For \R we can use \texttt{rApache} \citep{horner2013rapache} to develop this kind of scripted applications very similarly as with web scripting languages such as \texttt{php}. This works fine for relatively simple services that expose limited, predefined functionality. Scripted solutions give the developer flexibility to freely define input and output that are needed for a particular application. For example, we can write a script that generates a plot based on a couple of input parameters and returns a fixed size png image. Because scripts are stateless, multiple requests can be performed concurrently. A lot of the early work in this research has been based on this approach, which is a nice starting point but gets increasingly tricky once we move to more sophisticated applications.

The main limitation of this approach is that to support basic interactivity, retention of state needs to be implemented on the application level. However due to the complexicty of objects and data, this is much more involved than it is in e.g. \texttt{php}. For example a minimal application in statistics consists of the user uploading some data, performing some data manipulations and then creating a model, plot or report. When using scripts, the application developer needs to implement systems to manage and distinguish requests from various users and sessions, and store/load intermedate results in a database or disk. Doing this properly requires advanced \R and software engineering knowledge, and rapidly increases complexity as the application gets extended with additional scripts. Moreover storing objects/data on disk can introduce performance overhead. Because these problems will recur for almost any statistical application, we could benefit greatly from a system that supports retaining state by design.

Moreover predefined scripts are problematic because they divide developers and users in a way that is not very natural for scientific computing. The power of scripts in traditional web development is that they give give a lot of flexibility to the developer and very little to the user, which prevents malicous use of services. However in scientific computing, a script often  merely serves as a starting point for analysis. The user wants to be able to modify the script, or look at the data in another way by trying additional methods or different procedures. A system where clients can only perform prescripted actions severly handicaps the user and creates a lot of work for developers: because all functionality has to be prescripted, they are in charge of designing and implementing each possible action the user might want to perform. This is impractical for statistics because of the infinite amount of operations that can be performed on a dataset. For these reasons, the script approach does not scale well to many users or more complex applications.

\subsection{Stateful solution: client side process management}

Most existing bridges to \R take a stateful approach. Tools such as \texttt{Rserve} \citep{urbanek2013rserve} and \texttt{shiny} \citep{shiny} give each client a low-level interface to a private \R process over a (web)socket. This provides clients with freedom of running arbitrary \R code, which is great for implementing for example a webbased console or \texttt{IDE} such as \texttt{RStudio}. However the main problem with existing stateful solutions is lack of interoperability. Because these tools are in essense a remote \R console, they do not specify any standardized interface for calling methods, data I/O, etc. The advantage of the scripts approach discussed earlier was that clients simply pass parameters and the server returns output defined in the script such as a png image. However a low-level network interface requires extensive knowledge of \R internals to communicate. The client needs know how to call \R methods, interpret \R data structures, capture graphics, etc. These bridges are typically intended to be used in combination with dedicated clients. The \texttt{shiny} server for example comes with a set of predifined client widget templates that can be customized from within \R. The interface is not designed for integration with non-shiny software clients.

Stateful bridges also introduce some other difficulties. Systems that allocate a private \R process for each client can not support concurrent requests within a session. Each incoming request has to wait until the previous requests are finished for the process to become available. In addition to suboptimal performance, this can also be a source of instability. Procedures in data analysis are often unpredictable, and sometimes the \R process gets stuck or raises an unexpected error. In a local console we can easily interrupt or recover, but in an embedded system the server might become unresponsive causing the application to crash. Moreover, stateful servers are expensive and inefficient in terms of memory allocation. The server has to keep each \R process alive for the full duration of a session, even when idle. Memory that is in use by any single client does not free up until the user closes the application. This is particulary unfortunate because memory is often the main bottleneck in data intensive applications of scientific computing. Moreover, connectivity problems or ill behaved clients require the system to implement mechanisms to timeout and terminate inactive processes, or save and restore an entire session.

\subsection{A hybrid solution: functional state}

We can take the best of both worlds by abstracting the notion of state to a higher level. Interactivity and state in \OpenCPU is provided through persistency of \emph{objects} rather then a persistent \emph{process}. As it turns out, this is a natural and powerful definition of state within the functional paradigm. Functional programming emphasizes that output from methods depends only on their inputs and not on the program state. Therefore functional languages can support state without keeping an entire process alive: merely retaining the objects is sufficient. As was discussed before, this has obvious parallels with mathematics, but also maps beautifully to stateless protocols such as \HTTP. The notion of state as the set of session objects is already native to \R as is apparent from the \texttt{save.image} function. Exploiting this notion of state for \RPC results in an intuitive \API that allows us to get the benefits of both traditional stateless and statefull approaches without introducing additional complexity. This simple observation provides the foundations for a very flexible and efficient stateful \RPC system.

The way this works in \OpenCPU is as follows. The \OpenCPU \API defines a mapping between \HTTP requests to \R function calls. An \HTTP \texttt{POST} request to a functional endpoint results in a function call where the request parameters are mapped to the function arguments. After executing the function call, \OpenCPU stores all outputs (such as return value, graphics or files) on the server and a session \ID is given to the client. The session \ID can be used to control these outputs on the server in future requests. For example, a client can retrieve outputs in various formats, share them with others, or use stored \R objects as arguments in subsequent function calls. Hence to build an interactive application, the client simply performs function calls by passing around \ID's representing objects on the server, even though the individual requests are technically stateless. Apart from reduced complexity, this system makes parallel computing and asynchronous requests a natural part of the interaction. For example to compute $f(g(x),(h(y))$, the client could perform \RPC requests for $g(x)$ and $h(y)$ simultaneously and pass the resulting output \ID's to $f()$ in a second step. In an asynchronous client language such as \texttt{JavaScript} this is so natural that it does not require any effort from the user or application developer.

One important detail is that the \OpenCPU \API deliberately does not prescribe \emph{how} the server should implement storing of objects. The \API only specifies a system for performing \R function calls over \HTTP and assigning \ID's to objects. Different server implementations can use different strategies for retaining such objects. A native implementation simply serializes objects to a directory on the server and immideately kills the process. This is safe and easy, however saving data on disk can be slow. A more sophisticated implementation could keep objects in memory for a while longer, either by keeping the \R process alive or through some sort of in-memory database or memcached system. This nicely illustrates the kind of optimization that we can achieve by carefully decoupling server and client components.